{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question_answer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pilo1961/QuestionAnswer_System/blob/master/code/read_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bUXPVb2Gt6C",
        "colab_type": "text"
      },
      "source": [
        "# Sistema de Preguntas y Respuestas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opt1UfQoHS7S",
        "colab_type": "text"
      },
      "source": [
        "## Explore Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcXkOsHrAKeQ",
        "colab_type": "text"
      },
      "source": [
        "### Set up\n",
        "\n",
        "Para este analisis, empleamos el Dataset SQuAD version 1, mismo que se encuetra disponible en el siguiente [repositorio público](https://github.com/aswalin/SQuAD)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IOCSsPP5x67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries required\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6NsUQbISIkX",
        "colab_type": "code",
        "outputId": "f499e069-c710-4844-bc96-281b2d1a79e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load data from Google Drive Account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQfy4aI9SSfE",
        "colab_type": "text"
      },
      "source": [
        "### Training set\n",
        "\n",
        "El set de entrenamiento es una archivo *.json* anidado. La estructura del archivo es la siguiente\n",
        "\n",
        "+ Titulo\n",
        "+ Paragraph \n",
        "    + Context\n",
        "    + Qas\n",
        "        + Id\n",
        "        + Question\n",
        "        + Answers\n",
        "            + Text\n",
        "            + Answer start\n",
        "  \n",
        "\n",
        "En las siguientes celdas observamos los diferentes niveles de anidación de los datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98y7_KqQLWQm",
        "colab_type": "text"
      },
      "source": [
        "Los primero que observamos: hay un total de *442* párrafos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8wSClC-yOSE",
        "colab_type": "code",
        "outputId": "3175fd67-63a8-4c6b-ea8d-509777b42749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Lectura de datos\n",
        "path= \"/content/drive/My Drive/QA/train-v1.0.json\"\n",
        "with open(path) as f: \n",
        "    d = json.load(f) \n",
        "pd.set_option('max_colwidth', 500)\n",
        "df = pd.json_normalize(d['data'])  \n",
        "print(\"Daframe Size:\", df.shape)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daframe Size: (442, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the V...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of ...</td>\n",
              "      <td>Beyoncé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'context': 'Montana i/mɒnˈtænə/ is a state in the Western region of the United States. The state's name is derived from the Spanish word montaña (mountain). Montana has several nicknames, although none official, including \"Big Sky Country\" and \"The Treasure State\", and slogans that include \"Land of the Shining Mountains\" and more recently \"The Last Best Place\". Montana is ranked 4th in size, but 44th in population and 48th in population density of the 50 United States. The western third of...</td>\n",
              "      <td>Montana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'context': 'The phrase \"in whole or in part\" has been subject to much discussion by scholars of international humanitarian law. The International Criminal Tribunal for the Former Yugoslavia found in Prosecutor v. Radislav Krstic – Trial Chamber I – Judgment – IT-98-33 (2001) ICTY8 (2 August 2001) that Genocide had been committed. In Prosecutor v. Radislav Krstic – Appeals Chamber – Judgment – IT-98-33 (2004) ICTY 7 (19 April 2004) paragraphs 8, 9, 10, and 11 addressed the issue of in part ...</td>\n",
              "      <td>Genocide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'context': 'The emergence of resistance of bacteria to antibiotics is a common phenomenon. Emergence of resistance often reflects evolutionary processes that take place during antibiotic therapy. The antibiotic treatment may select for bacterial strains with physiologically or genetically enhanced capacity to survive high doses of antibiotics. Under certain conditions, it may result in preferential growth of resistant bacteria, while growth of susceptible bacteria is inhibited by the drug....</td>\n",
              "      <td>Antibiotics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            paragraphs                     title\n",
              "0  [{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the V...  University_of_Notre_Dame\n",
              "1  [{'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of ...                   Beyoncé\n",
              "2  [{'context': 'Montana i/mɒnˈtænə/ is a state in the Western region of the United States. The state's name is derived from the Spanish word montaña (mountain). Montana has several nicknames, although none official, including \"Big Sky Country\" and \"The Treasure State\", and slogans that include \"Land of the Shining Mountains\" and more recently \"The Last Best Place\". Montana is ranked 4th in size, but 44th in population and 48th in population density of the 50 United States. The western third of...                   Montana\n",
              "3  [{'context': 'The phrase \"in whole or in part\" has been subject to much discussion by scholars of international humanitarian law. The International Criminal Tribunal for the Former Yugoslavia found in Prosecutor v. Radislav Krstic – Trial Chamber I – Judgment – IT-98-33 (2001) ICTY8 (2 August 2001) that Genocide had been committed. In Prosecutor v. Radislav Krstic – Appeals Chamber – Judgment – IT-98-33 (2004) ICTY 7 (19 April 2004) paragraphs 8, 9, 10, and 11 addressed the issue of in part ...                  Genocide\n",
              "4  [{'context': 'The emergence of resistance of bacteria to antibiotics is a common phenomenon. Emergence of resistance often reflects evolutionary processes that take place during antibiotic therapy. The antibiotic treatment may select for bacterial strains with physiologically or genetically enhanced capacity to survive high doses of antibiotics. Under certain conditions, it may result in preferential growth of resistant bacteria, while growth of susceptible bacteria is inhibited by the drug....               Antibiotics"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjTIqWXPS1uC",
        "colab_type": "text"
      },
      "source": [
        "Existen un total de *18,891* contextos diferentes, como lo veremos a continuación.\n",
        "\n",
        "Además, si abrimos paragraph, encontramos otras dos columnas:\n",
        "  + qas - json anidado\n",
        "  + context - Escrito con el contexto de la pregunta\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Fjp7SZyeqe",
        "colab_type": "code",
        "outputId": "c46601fd-0d84-49ee-a6b2-ca0aa31a81d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "df=pd.json_normalize(data=d['data'],record_path=['paragraphs'],meta=['title'])\n",
        "print(\"Daframe Size:\", df.shape)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daframe Size: (18896, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>qas</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary rep...</td>\n",
              "      <td>[{'answers': [{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}], 'id': '5733be284776f41900661182', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'}, {'answers': [{'answer_start': 187, 'text': ' a copper statue of Christ'}], 'id': '5733be284776f4190066117f', 'question': 'What is in front of the Notre Dame Main Building?'}, {'answers': [{'answer_start': 279, 'text': 'the Main Building'}], 'id': '5733be284776f41900661180', 'question': 'The Basili...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artw...</td>\n",
              "      <td>[{'answers': [{'answer_start': 248, 'text': 'September 1876'}], 'id': '5733bf84d058e614000b61be', 'question': 'When did the Scholastic Magazine of Notre dame begin publishing?'}, {'answers': [{'answer_start': 441, 'text': 'twice'}], 'id': '5733bf84d058e614000b61bf', 'question': 'How often is Notre Dame's the Juggler published?'}, {'answers': [{'answer_start': 598, 'text': 'The Observer'}], 'id': '5733bf84d058e614000b61c0', 'question': 'What is the daily student paper at Notre Dame called?'},...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. Th...</td>\n",
              "      <td>[{'answers': [{'answer_start': 119, 'text': 'Rome'}], 'id': '5733bed24776f41900661188', 'question': 'Where is the headquarters of the Congregation of the Holy Cross?'}, {'answers': [{'answer_start': 145, 'text': 'Moreau Seminary'}], 'id': '5733bed24776f41900661189', 'question': 'What is the primary seminary of the Congregation of the Holy Cross?'}, {'answers': [{'answer_start': 234, 'text': 'Old College'}], 'id': '5733bed24776f4190066118a', 'question': 'What is the oldest structure at Notre ...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S...</td>\n",
              "      <td>[{'answers': [{'answer_start': 487, 'text': 'eight'}], 'id': '5733a6424776f41900660f51', 'question': 'How many BS level degrees are offered in the College of Engineering at Notre Dame?'}, {'answers': [{'answer_start': 46, 'text': '1920'}], 'id': '5733a6424776f41900660f4e', 'question': 'In what year was the College of Engineering at Notre Dame formed?'}, {'answers': [{'answer_start': 126, 'text': 'the College of Science'}], 'id': '5733a6424776f41900660f4f', 'question': 'Before the creation of...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All of Notre Dame's undergraduate students are a part of one of the five undergraduate colleges at the school or are in the First Year of Studies program. The First Year of Studies program was established in 1962 to guide incoming freshmen in their first year at the school before they have declared a major. Each student is given an academic advisor from the program who helps them to choose classes that give them exposure to any major in which they are interested. The program also includes a ...</td>\n",
              "      <td>[{'answers': [{'answer_start': 496, 'text': 'Learning Resource Center'}], 'id': '5733a70c4776f41900660f64', 'question': 'What entity provides help with the management of time for new students at Notre Dame?'}, {'answers': [{'answer_start': 68, 'text': 'five'}], 'id': '5733a70c4776f41900660f62', 'question': 'How many colleges for undergraduates are at Notre Dame?'}, {'answers': [{'answer_start': 155, 'text': 'The First Year of Studies program'}], 'id': '5733a70c4776f41900660f63', 'question': ...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               context  ...                     title\n",
              "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary rep...  ...  University_of_Notre_Dame\n",
              "1  As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artw...  ...  University_of_Notre_Dame\n",
              "2  The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. Th...  ...  University_of_Notre_Dame\n",
              "3  The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S...  ...  University_of_Notre_Dame\n",
              "4  All of Notre Dame's undergraduate students are a part of one of the five undergraduate colleges at the school or are in the First Year of Studies program. The First Year of Studies program was established in 1962 to guide incoming freshmen in their first year at the school before they have declared a major. Each student is given an academic advisor from the program who helps them to choose classes that give them exposure to any major in which they are interested. The program also includes a ...  ...  University_of_Notre_Dame\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdVR2yOkykhI",
        "colab_type": "code",
        "outputId": "f62d0d1b-3ffc-493c-c002-fe9dace30c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df=pd.json_normalize(data=d['data'],record_path=['paragraphs','qas'])#,meta=['title',['paragraph','context']])\n",
        "print(\"Daframe Size:\", df.shape)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daframe Size: (87636, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}]</td>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'answer_start': 187, 'text': ' a copper statue of Christ'}]</td>\n",
              "      <td>5733be284776f4190066117f</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'answer_start': 279, 'text': 'the Main Building'}]</td>\n",
              "      <td>5733be284776f41900661180</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame is beside to which structure?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'answer_start': 381, 'text': 'a Marian place of prayer and reflection'}]</td>\n",
              "      <td>5733be284776f41900661181</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'answer_start': 92, 'text': 'a golden statue of the Virgin Mary'}]</td>\n",
              "      <td>5733be284776f4190066117e</td>\n",
              "      <td>What sits on top of the Main Building at Notre Dame?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                      answers  ...                                                                      question\n",
              "0               [{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}]  ...       To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
              "1               [{'answer_start': 187, 'text': ' a copper statue of Christ'}]  ...                             What is in front of the Notre Dame Main Building?\n",
              "2                        [{'answer_start': 279, 'text': 'the Main Building'}]  ...  The Basilica of the Sacred heart at Notre Dame is beside to which structure?\n",
              "3  [{'answer_start': 381, 'text': 'a Marian place of prayer and reflection'}]  ...                                             What is the Grotto at Notre Dame?\n",
              "4        [{'answer_start': 92, 'text': 'a golden statue of the Virgin Mary'}]  ...                          What sits on top of the Main Building at Notre Dame?\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42EoJT7bVCr8",
        "colab_type": "text"
      },
      "source": [
        "Al abrir la columna qas encontramos 3 columnas mas\n",
        " + Question\n",
        " + Id\n",
        " + Answers - que es un json anidado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lywzzM4ypmm",
        "colab_type": "code",
        "outputId": "49f47131-0261-4351-c44d-1d2d84f556b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df=pd.json_normalize(data=d['data'],record_path=['paragraphs','qas','answers'])#,meta=['title',['paragraph','context']])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>187</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   answer_start                                     text\n",
              "0           515               Saint Bernadette Soubirous\n",
              "1           187                a copper statue of Christ\n",
              "2           279                        the Main Building\n",
              "3           381  a Marian place of prayer and reflection\n",
              "4            92       a golden statue of the Virgin Mary"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXai5hmQMOPs",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, al abrir la columna de answers encontramos las columnas:\n",
        "+ Answer_start - Información de la posición en la que comienza la respuesta.\n",
        "+ Text - Respuesta a la pregunta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzce5VzzVQ00",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "El dataset final de entrenamiento es:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBvcbbXTyvbX",
        "colab_type": "code",
        "outputId": "02b9b406-1a30-47c4-a5d6-2b46c023fcdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "df=pd.json_normalize(data=d['data'],\n",
        "                        record_path=['paragraphs','qas','answers'],\n",
        "                        record_prefix=None,\n",
        "                        meta_prefix=None,\n",
        "                        meta=['title',\n",
        "                              ['paragraph','context'],\n",
        "                              ['paragraph','qas','question'],\n",
        "                              ['paragraph','qas','id']])\n",
        "\n",
        "df.rename(columns={'paragraph.context':'context','paragraph.qas.question':'question','paragraph.qas.id':'id'},inplace=True)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(87636, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary rep...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>187</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary rep...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>5733be284776f4190066117f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary rep...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame is beside to which structure?</td>\n",
              "      <td>5733be284776f41900661180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary rep...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>5733be284776f41900661181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary rep...</td>\n",
              "      <td>What sits on top of the Main Building at Notre Dame?</td>\n",
              "      <td>5733be284776f4190066117e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   answer_start  ...                        id\n",
              "0           515  ...  5733be284776f41900661182\n",
              "1           187  ...  5733be284776f4190066117f\n",
              "2           279  ...  5733be284776f41900661180\n",
              "3           381  ...  5733be284776f41900661181\n",
              "4            92  ...  5733be284776f4190066117e\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utq1ZZoJFwro",
        "colab_type": "text"
      },
      "source": [
        "Los datos contienen 87636 preguntas para el set de entrenamiento y no contiene valores nulos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61jsOXHAy21X",
        "colab_type": "code",
        "outputId": "6db6a668-bbf5-4f7a-838a-7ed0f686dde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(\"dimensiones df\",df.shape)\n",
        "print(\"Nas \\n\", df.isna().sum())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dimensiones df (87636, 6)\n",
            "Nas \n",
            " answer_start    0\n",
            "text            0\n",
            "title           0\n",
            "context         0\n",
            "question        0\n",
            "id              0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOuaZQVmZcYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump training data in a pickle\n",
        "with open(\"/content/drive/My Drive/QA/df_train.pkl\", 'wb') as handle:\n",
        "    pickle.dump(df, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga_JJLgdhNF2",
        "colab_type": "text"
      },
      "source": [
        "### Validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H1ivaVqPW8v",
        "colab_type": "text"
      },
      "source": [
        "Los datos en el conjunto de validación también se encuentran anidados y organizados en la misma forma que los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzClQHSJhWAd",
        "colab_type": "code",
        "outputId": "b0fa0ca5-ca67-45e4-a8c6-1ab6d80243e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Lectura de datos\n",
        "path= \"/content/drive/My Drive/QA/dev-v1.0.json\"\n",
        "with open(path) as f: \n",
        "    d = json.load(f) \n",
        "\n",
        "df2 = pd.json_normalize(d['data'])  \n",
        "print(df2.shape)\n",
        "df2.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized...</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'context': 'One of the most famous people born in Warsaw was Maria Skłodowska-Curie, who achieved international recognition for her research on radioactivity and was the first female recipient of the Nobel Prize. Famous musicians include Władysław Szpilman and Frédéric Chopin. Though Chopin was born in the village of Żelazowa Wola, about 60 km (37 mi) from Warsaw, he moved to the city with his family when he was seven months old. Casimir Pulaski, a Polish general and hero of the American R...</td>\n",
              "      <td>Warsaw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, thei...</td>\n",
              "      <td>Normans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'context': 'Nikola Tesla (Serbian Cyrillic: Никола Тесла; 10 July 1856 – 7 January 1943) was a Serbian American inventor, electrical engineer, mechanical engineer, physicist, and futurist best known for his contributions to the design of the modern alternating current (AC) electricity supply system.', 'qas': [{'answers': [{'answer_start': 54, 'text': '1856'}, {'answer_start': 54, 'text': '1856\\xa0'}, {'answer_start': 54, 'text': '1856'}], 'id': '56df9e2838dc4217001520f6', 'question': 'In w...</td>\n",
              "      <td>Nikola_Tesla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'context': 'Computational complexity theory is a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm....</td>\n",
              "      <td>Computational_complexity_theory</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            paragraphs                            title\n",
              "0  [{'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized...                    Super_Bowl_50\n",
              "1  [{'context': 'One of the most famous people born in Warsaw was Maria Skłodowska-Curie, who achieved international recognition for her research on radioactivity and was the first female recipient of the Nobel Prize. Famous musicians include Władysław Szpilman and Frédéric Chopin. Though Chopin was born in the village of Żelazowa Wola, about 60 km (37 mi) from Warsaw, he moved to the city with his family when he was seven months old. Casimir Pulaski, a Polish general and hero of the American R...                           Warsaw\n",
              "2  [{'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, thei...                          Normans\n",
              "3  [{'context': 'Nikola Tesla (Serbian Cyrillic: Никола Тесла; 10 July 1856 – 7 January 1943) was a Serbian American inventor, electrical engineer, mechanical engineer, physicist, and futurist best known for his contributions to the design of the modern alternating current (AC) electricity supply system.', 'qas': [{'answers': [{'answer_start': 54, 'text': '1856'}, {'answer_start': 54, 'text': '1856\\xa0'}, {'answer_start': 54, 'text': '1856'}], 'id': '56df9e2838dc4217001520f6', 'question': 'In w...                     Nikola_Tesla\n",
              "4  [{'context': 'Computational complexity theory is a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm....  Computational_complexity_theory"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNt67N5shTiN",
        "colab_type": "code",
        "outputId": "1c6e53c0-a517-440a-d245-28fd8896149b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "df2=pd.json_normalize(data=d['data'],\n",
        "                        record_path=['paragraphs','qas','answers'],\n",
        "                        record_prefix=None,\n",
        "                        meta_prefix=None,\n",
        "                        meta=['title',\n",
        "                              ['paragraph','context'],\n",
        "                              ['paragraph','qas','question'],\n",
        "                              ['paragraph','qas','id']])\n",
        "\n",
        "df2.rename(columns={'paragraph.context':'context','paragraph.qas.question':'question','paragraph.qas.id':'id'},inplace=True)\n",
        "print(df2.shape)\n",
        "df2.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33615, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>176</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden a...</td>\n",
              "      <td>Which NFL team represented the AFC at Super Bowl 50?</td>\n",
              "      <td>56be4db0acb8001400a502ec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden a...</td>\n",
              "      <td>Which NFL team represented the AFC at Super Bowl 50?</td>\n",
              "      <td>56be4db0acb8001400a502ec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden a...</td>\n",
              "      <td>Which NFL team represented the AFC at Super Bowl 50?</td>\n",
              "      <td>56be4db0acb8001400a502ec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>248</td>\n",
              "      <td>Carolina Panthers</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden a...</td>\n",
              "      <td>Which NFL team represented the NFC at Super Bowl 50?</td>\n",
              "      <td>56be4db0acb8001400a502ed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>249</td>\n",
              "      <td>Carolina Panthers</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden a...</td>\n",
              "      <td>Which NFL team represented the NFC at Super Bowl 50?</td>\n",
              "      <td>56be4db0acb8001400a502ed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   answer_start  ...                        id\n",
              "0           176  ...  56be4db0acb8001400a502ec\n",
              "1           177  ...  56be4db0acb8001400a502ec\n",
              "2           177  ...  56be4db0acb8001400a502ec\n",
              "3           248  ...  56be4db0acb8001400a502ed\n",
              "4           249  ...  56be4db0acb8001400a502ed\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HxwsWOChur5",
        "colab_type": "code",
        "outputId": "aa2cfa93-739f-4b1c-ac00-896d5e0a9f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Check null values\n",
        "\n",
        "print(\"dimensiones df\",df2.shape)\n",
        "print(\"Nas \\n\", df2.isna().sum())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dimensiones df (33615, 6)\n",
            "Nas \n",
            " answer_start    0\n",
            "text            0\n",
            "title           0\n",
            "context         0\n",
            "question        0\n",
            "id              0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V0uvJwZh6DX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Dump data in a pickle\n",
        "with open(\"/content/drive/My Drive/QA/df_test.pkl\", 'wb') as handle:\n",
        "    pickle.dump(df2, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU5b-JDK-u3X",
        "colab_type": "text"
      },
      "source": [
        "### Análisis de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNRrQ52PhA4j",
        "colab_type": "code",
        "outputId": "b0c0d0f8-8f24-4793-a3e8-79bbcc0af64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Libraries required\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as  plt\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "nltk.download('punkt')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IV-WG5xhaHp",
        "colab_type": "text"
      },
      "source": [
        "En este apartado emplearemos **Text blob**, una paqueteria en python que nos ayuda a procesar lenguaje natural. Tiene muchas funciones para analizar la sintáxis, tokenizar, hacer preprocesamiento, frecuencias, entre otras.\n",
        "\n",
        "En el contexto de este análisis, lo utilizamos para extraer las oraciones de los contextos y para contar las palabras y oraciones que tenemos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHYDNVCzzw_i",
        "colab_type": "code",
        "outputId": "2768cad5-082b-43d5-924b-fd9789741565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creamos una lista con todos los contextos\n",
        "contextos=df[\"context\"].unique()\n",
        "len(contextos)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFPtPuHFci28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Numero de oraciones por contexto\n",
        "num_sent=[]\n",
        "for i in range(len(contextos)):\n",
        "  num_sent=np.append(num_sent, len(TextBlob(contextos[i]).sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LtCBzfeBBxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "52c4a808-effd-45cf-cf43-90bde711e8f5"
      },
      "source": [
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "g = sns.distplot(num_sent, kde=False, rug =True, color=\"b\", bins=15)\n",
        "g.set_title(\"Oraciones por contexto\")\n",
        "g.set_ylabel('Conteo')\n",
        "plt.show()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA_pTjBZmpX4",
        "colab_type": "code",
        "outputId": "133f672e-2d83-4615-eeb6-5ab3bcfa4f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "print(np.quantile(num_sent,.99))\n",
        "pd.DataFrame(num_sent).describe()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>18891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.953470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.326159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  18891.000000\n",
              "mean       4.953470\n",
              "std        2.326159\n",
              "min        1.000000\n",
              "25%        3.000000\n",
              "50%        5.000000\n",
              "75%        6.000000\n",
              "max       27.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-BR-3KpWnlC",
        "colab_type": "text"
      },
      "source": [
        "Observamos los estadísticos báscios del número de oraciones por contexto. \n",
        "La media es de 5 oraciones.\n",
        "Observamos que el 99% de los contextos tiene 12 o menos oraciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD5t2lombka8",
        "colab_type": "code",
        "outputId": "35d9c3d1-587c-42fc-86ac-5533710207dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#El número total de oraciones que tienen los contextos\n",
        "sentence_corpus= TextBlob(\" \".join(contextos)).sentences\n",
        "len(sentence_corpus)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92659"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rExtELdaWN68",
        "colab_type": "text"
      },
      "source": [
        "También observamos que los contextos de entrenamiento tienen  un corpus de 2220093 palabras.  \n",
        "Observamos que el promedio de palabras por oración es de 23.9 y que el 99% de las oraciones tienen menos de 63 palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGAZw1BxfEJL",
        "colab_type": "code",
        "outputId": "da56c52b-e8c2-42fc-f122-173ded43013a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Numero de palabras en todos los contextos\n",
        "corpus= TextBlob(\" \".join(contextos)).words\n",
        "len(corpus)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2220093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXCQtaNsbmrR",
        "colab_type": "code",
        "outputId": "cea6a4f0-aa69-423b-b3a5-318f8a1d5a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "#palabras por oracion\n",
        "word_sent=[len(sentence.words) for sentence in sentence_corpus]\n",
        "\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "g = sns.distplot(word_sent, kde=False, rug =True, color=\"b\", bins=15)\n",
        "g.set_title(\"Palabras por oración\")\n",
        "g.set_ylabel('Conteo')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"max= \",max(word_sent))\n",
        "print(\"min= \",min(word_sent))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "max=  323\n",
            "min=  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44fhnu1pXKzP",
        "colab_type": "code",
        "outputId": "56244617-c524-48cf-8b9b-2ce151bb0afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "print(np.quantile(word_sent,.99))\n",
        "pd.DataFrame(word_sent).describe()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>92659.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.959820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.137481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>323.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  92659.000000\n",
              "mean      23.959820\n",
              "std       12.137481\n",
              "min        0.000000\n",
              "25%       16.000000\n",
              "50%       22.000000\n",
              "75%       30.000000\n",
              "max      323.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FAUvx07lx8p",
        "colab_type": "text"
      },
      "source": [
        "## Embedding word2Vec\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC1m06HxGaTl",
        "colab_type": "text"
      },
      "source": [
        "A continuación construimos una representacion matricial de las palabras, dado el contexto en el que aparecen en nuestro corpus.\n",
        "Para ello, probamos el embedding word2Vec.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ2nXwmrcZmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import cython\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKD0P_gDudSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hace el corpus\n",
        "data=[]\n",
        "i=0\n",
        "for cont in contextos: # para cada contexto\n",
        "  sample=cont\n",
        "  for sent in sent_tokenize(sample): # Extrae las oraciones\n",
        "    temp=[]\n",
        "    for j in word_tokenize(sent): #Extrae las palabras\n",
        "      temp.append(j.lower())\n",
        "\n",
        "    data.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYmlQi7x2Oq-",
        "colab_type": "code",
        "outputId": "60ed85c6-bbf5-419b-b124-74d5fd12f9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# La estructura que queda de data tiene la forma de lista de oraciones.\n",
        "# Cada oracion es una lista de palabras\n",
        "# Con este metodo tenemos 93576 oraciones, anteriormente teniamos 92659\n",
        "# Tiene un 0.1% de variacion\n",
        "print(len(data))\n",
        "data[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['atop',\n",
              " 'the',\n",
              " 'main',\n",
              " 'building',\n",
              " \"'s\",\n",
              " 'gold',\n",
              " 'dome',\n",
              " 'is',\n",
              " 'a',\n",
              " 'golden',\n",
              " 'statue',\n",
              " 'of',\n",
              " 'the',\n",
              " 'virgin',\n",
              " 'mary',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dEyLQxi4mC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entrena un modelo Word2Vec CBOW con nuestro corpus\n",
        "model1 = gensim.models.Word2Vec(data, min_count = 1,  size = 100, window = 5,workers=8) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbZN3yzr4zYf",
        "colab_type": "code",
        "outputId": "9adba767-9134-42a3-a340-8f0a0480596e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Longitud del vocabulario\n",
        "len(model1.wv.vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97680"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUl8fCehKmTB",
        "colab_type": "code",
        "outputId": "7a8a97fe-9fb5-437b-9477-821717971ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# La representaciones las podemos ver:\n",
        "model1['building']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.53325254, -1.1205275 ,  0.447919  , -0.16391894,  1.1319224 ,\n",
              "       -0.7087768 , -0.03862454, -0.63492316, -0.8012175 ,  0.40396783,\n",
              "        0.59878665, -0.00822338, -0.43349317,  0.8104244 ,  0.09412549,\n",
              "        1.3043555 ,  0.852056  ,  0.5326712 ,  0.5236839 ,  0.13958977,\n",
              "       -0.08586107,  0.3186869 ,  1.1108162 ,  0.62419516,  0.3393669 ,\n",
              "       -0.9630213 ,  0.60256934, -1.3430564 ,  0.14466654,  0.37595955,\n",
              "       -0.7461374 , -0.9114267 ,  0.17378269,  1.369758  , -0.10141047,\n",
              "       -0.15330894, -1.1978418 ,  0.11703686,  0.5602496 , -0.19608802,\n",
              "       -0.19263071,  0.27364194,  0.6356784 , -0.17845902,  0.64991486,\n",
              "        0.14662723,  0.41397777, -0.39706194, -0.55872536, -0.73583907,\n",
              "       -1.2003419 ,  1.558361  ,  0.24621573,  0.06223533,  0.18800636,\n",
              "       -0.6977862 , -1.2117637 , -0.5185307 , -0.899079  ,  0.76641023,\n",
              "        0.7879984 , -0.27522948, -0.24981868, -0.85819894, -0.8728474 ,\n",
              "        0.65737945, -0.01983334, -1.386096  ,  0.00473466,  0.9536095 ,\n",
              "        0.6194776 ,  0.56111425, -0.6652947 ,  0.5270821 , -0.57039833,\n",
              "       -0.71984446, -0.39393327,  0.05726049, -1.0479728 ,  0.38566574,\n",
              "       -0.4415102 ,  0.6951626 ,  0.19194554, -0.49177998,  0.09546553,\n",
              "       -0.06697533,  1.9205927 , -0.26898804,  0.80096596,  0.5213332 ,\n",
              "        0.36886102, -0.77538204, -0.97081655, -0.9713714 , -0.34453756,\n",
              "        0.07384595, -0.29723737,  0.5006416 , -0.70869267,  0.21249817],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkyrQb7BPUD8",
        "colab_type": "code",
        "outputId": "21d92e01-4a20-4ef4-c36b-2e6e04a88dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Buscamos palabras similares a otras\n",
        "# Una pregunta es:\n",
        "print(\"La pregunta 1 es: \")\n",
        "print(df[\"question\"][1])\n",
        "print(\"Palabras similares a building: \")\n",
        "print(model1.wv.most_similar(positive=['building'], topn=5))\n",
        "print(\"Palabras similares a notre: \")\n",
        "print(model1.wv.most_similar(positive=['notre'], topn=5))\n",
        "print(\"Palabras similares a dame: \")\n",
        "print(model1.wv.most_similar(positive=['dame'], topn=5))\n",
        "print(\"Palabras similares a front: \")\n",
        "print(model1.wv.most_similar(positive=['front'], topn=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La pregunta 1 es: \n",
            "What is in front of the Notre Dame Main Building?\n",
            "Palabras similares a building: \n",
            "[('centre', 0.8550713062286377), ('campus', 0.8209539651870728), ('station', 0.8129981756210327), ('site', 0.8091264963150024), ('shopping', 0.8047854900360107)]\n",
            "Palabras similares a notre: \n",
            "[('dame', 0.9548112154006958), ('yale', 0.8984901309013367), ('dean', 0.8938989639282227), ('harvard', 0.8925623893737793), ('cricket', 0.8903105854988098)]\n",
            "Palabras similares a dame: \n",
            "[('notre', 0.9548113346099854), ('yale', 0.902605414390564), ('princeton', 0.894440233707428), ('fame', 0.8870726823806763), ('cricket', 0.8773947954177856)]\n",
            "Palabras similares a front: \n",
            "[('edge', 0.8561083078384399), ('shores', 0.8450071811676025), ('corner', 0.829058051109314), ('town', 0.8233914375305176), ('isthmus', 0.8201740980148315)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15k9n6Oh5Qd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entrena un modelo Word2Vec skip-gram con nuestro corpus\n",
        "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, window = 5, sg = 1, workers=8)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjcpXzU1Pwy5",
        "colab_type": "code",
        "outputId": "0004dbe8-b3b9-40fc-98ad-eceef3fea9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Buscamos palabras similares a otras\n",
        "# Una pregunta es:\n",
        "print(\"La pregunta 1 es: \")\n",
        "print(df[\"question\"][1])\n",
        "print(\"Palabras similares a building: \")\n",
        "print(model2.wv.most_similar(positive=['building'], topn=5))\n",
        "print(\"Palabras similares a notre: \")\n",
        "print(model2.wv.most_similar(positive=['notre'], topn=5))\n",
        "print(\"Palabras similares a dame: \")\n",
        "print(model2.wv.most_similar(positive=['dame'], topn=5))\n",
        "print(\"Palabras similares a front: \")\n",
        "print(model2.wv.most_similar(positive=['front'], topn=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La pregunta 1 es: \n",
            "What is in front of the Notre Dame Main Building?\n",
            "Palabras similares a building: \n",
            "[('construction', 0.8210124969482422), ('constructing', 0.7994292378425598), ('constructed', 0.7942978143692017), ('buildings', 0.7921033501625061), ('housed', 0.7907477617263794)]\n",
            "Palabras similares a notre: \n",
            "[('dame', 0.9722816944122314), ('coach', 0.8675147891044617), ('yankee', 0.8638318777084351), ('cambridge', 0.8634951114654541), ('ivy', 0.8602300882339478)]\n",
            "Palabras similares a dame: \n",
            "[('notre', 0.972281813621521), ('coach', 0.8586839437484741), ('ku', 0.8406217694282532), ('ivy', 0.8369539976119995), ('fame', 0.8352218866348267)]\n",
            "Palabras similares a front: \n",
            "[('wing', 0.8132989406585693), ('38th', 0.8001183271408081), ('beside', 0.7942988276481628), ('battlefield', 0.7939717173576355), ('rear', 0.7908223867416382)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOrIfIysDgxx",
        "colab_type": "text"
      },
      "source": [
        "Hay que notar que las probabilidades son diferentes para el modelo de CBOW y de skip-grams aunque se entrenaron con el mismo vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iGeYBcb-LYC",
        "colab_type": "code",
        "outputId": "e8e9e517-3872-475e-ff4b-24616f0e3583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "i=36\n",
        "q=word_tokenize(df[\"question\"][i].lower())\n",
        "\n",
        "print(\"Pregunta:\")\n",
        "print(q)\n",
        "\n",
        "\n",
        "print(\"La respuesta indicada es:\")\n",
        "print(df[\"text\"][i])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Palabras mas parecidas con CBOW\")\n",
        "print(model1.wv.most_similar(positive=q, topn=6))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Palabras mas parecidas con skip-grams\")\n",
        "print(model2.wv.most_similar(positive=q, topn=6))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pregunta:\n",
            "['in', 'what', 'year', 'was', 'the', 'theodore', 'm.', 'hesburgh', 'library', 'at', 'notre', 'dame', 'finished', '?']\n",
            "La respuesta indicada es:\n",
            "1963\n",
            "\n",
            "\n",
            "Palabras mas parecidas con CBOW\n",
            "[('philharmonic', 0.9165336489677429), ('olympia', 0.9137911200523376), ('sparta', 0.9082456827163696), ('coach', 0.9035303592681885), ('celebration', 0.897372305393219), ('herald', 0.8960696458816528)]\n",
            "\n",
            "\n",
            "Palabras mas parecidas con skip-grams\n",
            "[('bennett', 0.9358039498329163), ('honoring', 0.9314770698547363), ('vh1', 0.9259068369865417), ('longest-reigning', 0.9231418371200562), ('22nd', 0.9228159189224243), ('seminar', 0.9227113723754883)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un-PdAurFMZL",
        "colab_type": "text"
      },
      "source": [
        "Las predicciones que están dando ambos modelos son muy malas. Las palabras mas parecidas no tienen nada que ver con la respuesta a la pregunta.  \n",
        "Notese que todavía no tenemos ningún entrenamiento en el modelo. Hasta ahora lo único que tenemos es una representacion matricial de las palabras, dado el contexto en el que aparecen en nuestro corpus.   \n",
        "Sobre esa información debemos contruir un modelo que ligue nuestras representaciones con el sentido de la pregunta. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj-25UdtaJDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Dump model1 in a pickle\n",
        " with open(\"/content/drive/My Drive/QA/word2vec_cbow.pkl\", 'wb') as handle:\n",
        "    pickle.dump(model1, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Nocc3-aKAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump model2 in a pickle\n",
        "\n",
        "with open(\"/content/drive/My Drive/QA/word2vec_skipgram.pkl\", 'wb') as handle:\n",
        "    pickle.dump(model2, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}