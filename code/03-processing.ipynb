{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Processing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pilo1961/QuestionAnswer_System/blob/master/code/Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBYUBtDapR9v",
        "colab_type": "text"
      },
      "source": [
        "# Sistema de Preguntas y Respuestas\n",
        "## 03. Processing Data and Feature engineering\n",
        "\n",
        "\n",
        "En el presente notebook se realiza el preprocesamiento de los datos que van a ser empleados en la implementación de los modelos supervisado. En el intermedio, implementamos dos modelos no supervisados, obteniendo accuracies de 59.9 y 36.9 por ciento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po2rOL7Xhd6l",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT3qdiARpj5G",
        "colab_type": "code",
        "outputId": "2ce12940-c56b-434b-fcf6-fb4c26f02f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Imports\n",
        "\n",
        "import pickle\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIHvOI8TpU3d",
        "colab_type": "code",
        "outputId": "25024e8a-8d07-4387-a07e-305fb54df6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAPr24iiplIm",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6zlDoER-86z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load train data from pickle\n",
        "with open(\"/content/drive/My Drive/QA/df_train.pkl\", \"rb\") as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "train_data.drop(columns=['id','title'],inplace=True)\n",
        "train_data.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQaneygQ_OQX",
        "colab_type": "code",
        "outputId": "d4883011-a19a-4cb8-ec84-7404e92a5adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(87636, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>187</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   answer_start  ...                                           question\n",
              "0           515  ...  To whom did the Virgin Mary allegedly appear i...\n",
              "1           187  ...  What is in front of the Notre Dame Main Building?\n",
              "2           279  ...  The Basilica of the Sacred heart at Notre Dame...\n",
              "3           381  ...                  What is the Grotto at Notre Dame?\n",
              "4            92  ...  What sits on top of the Main Building at Notre...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uubTnOIX_Ut4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load embeddings from pickle\n",
        "# Train question embedding\n",
        "with open(\"/content/drive/My Drive/QA/train_question.pkl\", \"rb\") as f:\n",
        "    train_question_emb = pickle.load(f)\n",
        "\n",
        "# Train context embeddings\n",
        "with open(\"/content/drive/My Drive/QA/train_dict.pkl\", \"rb\") as f:\n",
        "    train_dict = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6aEpdhfxs5t",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Format data\n",
        "\n",
        "Ordenamos los datos en forma de listas anidadas.\n",
        "* La variable context_embedding es una lista anidada con los embeddings de las oraciones del contexto.\n",
        "* La variable contexts contiene las oraciones tokenizadas del contexto\n",
        "* q_embedding tiene los embeddings de las preguntas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE-nqZY4Cty9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Genera una lista de listas para los contextos\n",
        "# \\y para los embeddings de los contextos\n",
        "\n",
        "contexts=[]\n",
        "context_embedding=[]\n",
        "last_context=[]\n",
        "\n",
        "for context in train_data['context']:\n",
        "\n",
        "  if context == last_context:# Si es el mismo contexto usa lo que ya calculamos\n",
        "    contexts.append(temp)\n",
        "    context_embedding.append(temp_emb)\n",
        "    continue\n",
        "  \n",
        "  temp=[]\n",
        "  temp_emb=[]\n",
        "  for sent in sent_tokenize(context):\n",
        "    s=sent.lower()\n",
        "    temp.append(s)\n",
        "    e=train_dict[s]\n",
        "    temp_emb.append(e)\n",
        "  \n",
        "  contexts.append(temp)\n",
        "  context_embedding.append(temp_emb)\n",
        "  last_context=context\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2rVag0AHjvZ",
        "colab_type": "code",
        "outputId": "1e5fd9e4-c040-4e37-f094-ffcb5fc1b582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Todas las variables tienen la misma longitud que el df original\n",
        "print(len(context_embedding))\n",
        "print(len(contexts))\n",
        "print(len(train_question_emb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87636\n",
            "87636\n",
            "87636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEhaUCYyhbK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_context_embedding=pd.DataFrame(context_embedding)\n",
        "df_contexts=pd.DataFrame(contexts)\n",
        "df_question_embedding=pd.DataFrame(train_question_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4371R2dAPfxM",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Generación variable target\n",
        "\n",
        "Para hacer la variable target buscamos la respuesta literal dentro del contexto. El target es la oración donde aparece la respuesta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdq5A5e3FB7j",
        "colab_type": "code",
        "outputId": "11643266-a6b5-48d9-9a75-47c597b19055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>187</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   answer_start  ...                                           question\n",
              "0           515  ...  To whom did the Virgin Mary allegedly appear i...\n",
              "1           187  ...  What is in front of the Notre Dame Main Building?\n",
              "2           279  ...  The Basilica of the Sacred heart at Notre Dame...\n",
              "3           381  ...                  What is the Grotto at Notre Dame?\n",
              "4            92  ...  What sits on top of the Main Building at Notre...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Yg0BM4GPgJ",
        "colab_type": "code",
        "outputId": "844d7484-8258-4b96-85ee-e7400a36da7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Busca la oracion que tiene la respuesta literal dentro del contexto\n",
        "# guarda la posicion de la oracion dentro del contexto\n",
        "# Si no la encuentra deja target = -1\n",
        "train_data[\"target\"]=-1\n",
        "for i in range (len(train_data)):\n",
        "  respuesta=train_data[\"text\"][i].lower()\n",
        "  for j, sent in enumerate(contexts[i]):\n",
        "    if respuesta in sent: \n",
        "      train_data[\"target\"][i] = j\n",
        "      break\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JubYzxmO6rrX",
        "colab_type": "code",
        "outputId": "3d6635f2-970c-482a-9d8a-46d763608050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#casos que no se encontro la respuesta\n",
        "sum(train_data[\"target\"]==-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "981"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C0owgNb6E7d",
        "colab_type": "text"
      },
      "source": [
        "Encontramos 981 casos que representan el 1.11 por ciento. \n",
        "Dado que se trata de un problema de comprehensión de lectura y un supuesto en el planteamiento es que encontramos la respuesta a la pregunta literal en el contexto, procedemos a quitar esos casos de nuestro análisis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km2O-RsYkkuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quitamos las filas que no tienen target en el df\n",
        "index = np.where(train_data[\"target\"]==-1)\n",
        "contexts = np.delete(contexts,index,axis=0)\n",
        "context_embedding = np.delete(context_embedding,index,axis=0)\n",
        "train_question_emb = np.delete(train_question_emb,index,axis=0)\n",
        "\n",
        "# Quitamos las filas que no tienen target en el df\n",
        "index=train_data[\"target\"]==-1\n",
        "train_data=train_data[-index].reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9xKuZTkk04",
        "colab_type": "code",
        "outputId": "32b919c8-d593-4705-a6cb-9612d41cae46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# La nueva longitud de los datos\n",
        "print(train_data.shape)\n",
        "print(len(context_embedding))\n",
        "print(len(contexts))\n",
        "print(len(train_question_emb))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(86655, 6)\n",
            "86655\n",
            "86655\n",
            "86655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6NttZWBS-mI",
        "colab_type": "code",
        "outputId": "aec82891-41ea-4bd8-f3bb-9fe55fb978a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "g = sns.distplot(train_data[\"target\"], kde=False, rug =True, color=\"b\", bins=20)\n",
        "g.set_title(\"Distribución de variable target\")\n",
        "g.set_ylabel('Conteo')\n",
        "g.set_xlabel('Target')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEcCAYAAAD+73KmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfVxUZd4/8M/MwIAINsACDtrq2gY3iikEmQSZqIiGUpZC3mnKmobGupUkZYKhpog96aK21o3r3q6Utw/kI9KWabWZdqtIttly40OCgAwUzwMz1+8PX85P4mlm4BoUP+/Xq9cLznWuc76cufIz55oz5yiEEAJERESSKLu7ACIi6tkYNEREJBWDhoiIpGLQEBGRVAwaIiKSikFDRERSMWjIJpKTk5GRkdEl2yoqKkJAQAAMBgMAYMaMGdixY0eXbPtmAQEBuHz5crNlRqMR8fHxXbq/pKQkvP322122PWt9/PHHiIuLM2vd9evXY9GiRW22h4eH46uvvuqq0ug2x6ChTgsPD8d9992HgIAABAUFITY2Ftu3b4fRaDStk5qaigULFpi1rY7+gfL29sapU6egUqk6XXt7Tp06hbvvvrvZsnfeeQcjR47E1KlTpe67O0yePBn/9V//1a01HD9+HA8//PAdu/+eyq67C6CeYdOmTQgJCUFVVRW++eYbrFy5Enl5eVi1alWX7qepqQl2dt03bF988cVu27dM3X1cu0pP+Tt6Gp7RUJdycXHBmDFj8M4772D37t04f/48gObTQzqdDvPmzUNQUBAeeOABTJ8+HUajEYmJiSgqKsJzzz2HgIAAbN68GT/99BN8fX2xY8cOPPLII3jmmWdMy5qamkz7vXTpEp588kkEBgYiPj4elZWVAFp/h3rzWZPBYMCmTZswduxYBAQEYMqUKSguLgYA+Pr64uLFiwCAqqoqvPzyy3jwwQcxevRobNiwwXTGtmvXLjz11FNIS0tDcHAwwsPD8fnnn7d5jM6dO4fHH38cAQEB+NOf/oSGhoZm7Z999hmio6NNZ4f/+te/Wt1OSkoK0tLSmi2Lj49HZmYmAOAvf/mL6e+aOHEicnNzTevt2rULsbGxeOONNzBixAisX7/e9HfcsGLFCowaNQqBgYGYMmUKTp482Wxfer0ef/rTnxAQEIDHH3+8zTqNRqOplhEjRmDhwoWm1+dmtbW1ePbZZ1FaWoqAgAAEBASgpKQEeXl5iImJQVBQEEJDQ5Gamgq9Xm/q5+vri23btiEiIgIREREAgM2bNyM0NBShoaHYsWNHs9dSr9cjLS0NjzzyCEJCQpCcnIz6+vo2909dQBB10ujRo8WXX37ZYvmoUaPEtm3bhBBCLF68WLz11ltCCCHWrl0rli5dKvR6vdDr9eLEiRPCaDS2uq3Lly8LHx8fkZiYKGpqakRdXZ1pWWNjoxBCiKefflqEhoaKH374QdTU1Ijnn39evPTSS0IIIb7++msRFhbWZr2bN28WUVFRoqCgQBiNRvH9998LnU4nhBDCx8dHXLhwQQghRGJionjuuedEVVWVuHz5soiIiBAfffSREEKInTt3isGDB4sPP/xQNDU1iW3btomHHnrI9DfdrKGhQTzyyCMiMzNT6PV6cfDgQTF48GDTsfnuu+/Egw8+KE6fPi2amprErl27xOjRo0VDQ0OLbX3zzTfi4YcfNu2nsrJSDB06VFy9elUIIcSBAwfE1atXhcFgEPv37xfDhg0TJSUlppr9/PzE1q1bRWNjo6irqxM7d+4UsbGxpu3v2bNH6HQ60djYKD744AMREhIi6uvrhRBCrFu3TgwePFgcPHhQ6PV68f7774vRo0cLvV7f4hhv2bJFTJ06VRQXF4uGhgaxdOlS8cILL7T4e9p6vc6ePStOnTolGhsbxeXLl0VkZKTIzMw0tfv4+IhZs2aJiooKUVdXJz7//HMREhIizp8/L2pra8VLL73U7LVcuXKlmDdvnqioqBBVVVVi3rx5Yu3atW3unzqPZzQkjaenJ37++ecWy+3s7FBWVoaioiLY29sjKCgICoWi3W0lJCTAyckJjo6OrbZHR0fDx8cHTk5OWLhwIQ4dOmS6WKA9O3bswMKFCzFo0CAoFAr8x3/8B1xdXZutYzAYcODAAbz00ktwdnZG//79MXv2bHz88cemdby9vTFt2jSoVCo8/vjjKCsrw7Vr11rs78yZM2hsbMQzzzwDe3t7REZGYujQoab2Dz/8EDExMRg2bJhpW/b29jh9+nSLbd04bjfONHJycjB8+HB4eXkBACZMmAAvLy8olUpMnDgRAwYMQF5enqm/p6cnZsyYATs7u1aPa3R0NFxdXWFnZ4e4uDjo9XoUFhaa2ocMGYLIyEjY29tj9uzZ0Ov1OHPmTIvtZGVl4YUXXkDfvn2hVqvx/PPPIycnp9kZaXv8/f0xfPhw2NnZoX///oiJicGJEyearTN37lxoNBo4Ojri4MGDmDJlCu6991706tULCQkJpvWEEPjoo4/w6quvQqPRwNnZGfPmzcP+/fvNqoWsw8lMkqakpAR33XVXi+V/+MMf8Oc//9l0hVNMTAzmzp3b7rb69u3bbrtWqzX97O3tjcbGRlRUVHRY49WrV/Hb3/623XUqKirQ2NgIb2/vZvu4eVrlN7/5jennXr16Abg+FfRrpaWl8PLyahasN2+3qKgIe/bswX//93+bljU2NqK0tLTFthQKBSZOnIh9+/YhODgYe/fuxeTJk03te/bsQWZmJq5cuWKq5+Zj0tEx/eCDD/A///M/KC0thUKhQHV1dZv9lUolvLy8Wq2zqKgICxYsgFKpbLZ+eXm5KRTbU1hYiNWrVyM/Px91dXUwGAwYMmRIs3Vufv1LS0vh7+/faptOp0NdXR2mTJliWiaEaHbhCnU9Bg1JkZeXh5KSEtx///0t2pydnZGUlISkpCScP38ezzzzDIYOHYqRI0e2ub2OznhufK5y42d7e3u4urqiV69eqK+vN7UZDAbodDrT73379sWlS5fg4+PT5rZdXV1hb2+PoqIi/P73vzftw5x/JH/Nw8MDJSUlEEKY/qaioiLT1W1arRbPPfcc4uPjzdpeVFQU4uLiMHfuXOTl5ZkuIb9y5Qpee+01bNmyBQEBAVCpVIiOjm7Wt71jevLkSbz//vvYsmUL7r33XiiVSgQHB0PcdLP3q1evmn42Go0oKSmBp6dni2317dsXb7zxRqtj4ddaq2nZsmUYPHgw3nzzTTg7O2PLli3Iyclps5+np2ezNwE3jw1XV1c4Ojpi//79rb5+HY0zsg6nzqhLVVdX47PPPsOLL76IyZMnw9fXt8U6n332GS5evAghBFxcXKBSqUz/g//mN79p8d0Vc3z88cf497//jbq6Orz77rsYP348VCoVfve736GhoQFHjhxBY2MjNm7c2OyD5KlTp+Ldd9/FhQsXIITAv/71rxZnQiqVCpGRkXj77bdRXV2NK1euIDMzs9nZg7luTAFt3boVjY2NOHz4MM6ePdusnqysLJw5cwZCCNTW1uLIkSOorq5udXuDBw+Gq6srXnvtNYSGhqJPnz4AgLq6OigUCri5uQEAdu7ciR9//NHsOmtqaqBSqeDm5oampib8+c9/blHDd999h8OHD6OpqQl//etfoVarMWzYsBbbeuqpp/DOO++Yzqx0Oh0++eSTVvfr7u6OyspKVFVVNauld+/e6N27NwoKCrB9+/Z2a4+MjMSuXbtQUFCAuro6bNiwwdSmVCoxdepUvPHGGygvLwdw/cz72LFjbe6fOo9BQ13ixpVio0aNwqZNmzB79uw2L22+ePEiZs+ejYCAAMTExOCpp57Cgw8+COD6XPvGjRsRFBSEDz74wOz9R0dHIykpCQ899BD0ej2WLFkC4PpVcCkpKXjttdfw8MMPo1evXs2mfGbPno0JEyYgLi4OgYGBWLJkSYurwABg6dKl6NWrF8aOHYvp06cjKioKTzzxhCWHCACgVquxfv167N69Gw888AAOHDiAcePGmdqHDh2K5cuXIzU1FcHBwYiIiMCuXbva3WZUVBS++uorREVFmZb9/ve/R1xcHGJjYxESEoLz588jMDDQ7DpDQ0MRFhaG8ePHIzw8HA4ODs2moABgzJgxOHDgAIKDg5GdnY3169fD3t6+xbZmzpyJ8PBwxMXFISAgANOmTWv2WdHN7rnnHjz66KMYO3YsgoKCUFJSgsWLF2Pfvn0IDAzE0qVLMXHixHZrHzVqFGbMmIGZM2di3LhxpvBTq9UAgMTERAwYMADTpk1DYGAgZs2aZfrsqbX9U+cphOCDz4io5yooKEBUVBTOnj3L79h0E57REFGPk5ubC71ej59//hnp6ekYPXo0Q6YbMWiIqMfJysrCyJEjMW7cOKhUKixbtqy7S7qjceqMiIik4hkNERFJxaAhIiKpGDRERCSVzS7DmD9/Pn766ScolUo4OTlh6dKl8PPzQ2FhIZKSklBZWQmNRoO0tDQMHDgQAKS0mauiogZGo+UfX7m7O6O8vPUv13Un1mUZ1mUZ1mWZnliXUqmAq2vvVttsdjFAVVUVXFxcAACffPIJMjIysHv3bsycORNPPPEEoqOjkZ2djZ07d2Lr1q0AIKXNXOXl1VYFjYeHC8rKbr1vFbMuy7Auy7Auy/TEupRKBdzdnVtv60xRlrgRMsD125QoFAqUl5fj3Llzpm80R0VF4dy5c9DpdFLaiIjI9mz6DaYlS5bgyy+/hBAC77//vunGhDceyatSqeDp6Yni4mIIIbq87cZ9n4iIyHZsGjQrV64EcP325WvWrMHChQttuXuLtHUKaA4PD5eOV+oGrMsyrMsyrMsyd1Jd3XJPhsceewzJycno27cvSkpKYDAYoFKpYDAYUFpaCq1WCyFEl7dZgp/R2Abrsgzrsgzrssxt/RlNTU1Ns2dCfPrpp7jrrrvg7u4OPz8/7Nu3DwCwb98++Pn5wc3NTUobERHZnk2uOrt27Rrmz5+Puro6KJVK3HXXXVi8eDGGDBmCgoICJCUl4ZdffkGfPn2QlpaGQYMGAYCUNnPxjMY2WJdlWJdlWJdlZJ3R8F5nbWDQ2AbrsgzrsgzrsoysoOF9s7tYVa0eNQ1NVvV1sLeDHe/VQEQ9DIOmi9XVN+HE99Y9lS/Yzwt2DnxJiKhn4ftnIiKSikFDRERSMWiIiEgqBg0REUnFoCEiIqkYNEREJBWDhoiIpGLQEBGRVAwaIiKSikFDRERSMWiIiEgqBg0REUnFoCEiIqkYNEREJBWDhoiIpGLQEBGRVAwaIiKSikFDRERSMWiIiEgqBg0REUnFoCEiIqkYNEREJBWDhoiIpGLQEBGRVHa22ElFRQVefvllXLp0CWq1GgMGDEBqairc3Nzg6+sLHx8fKJXXM2/NmjXw9fUFAHz66adYs2YNDAYDhgwZglWrVqFXr16daiMiItuyyRmNQqHAnDlzkJOTg7179+Luu+/G2rVrTe1ZWVnIzs5Gdna2KWRqamqwdOlSbNq0Cbm5uejduzc++OCDTrUREZHt2SRoNBoNRowYYfp9+PDhKCoqarfP0aNH4e/vj4EDBwIAYmNjcfDgwU61ERGR7dlk6uxmRqMR27dvR3h4uGnZjBkzYDAY8PDDDyMhIQFqtRrFxcXw9vY2rePt7Y3i4mIAsLqNiIhsz+ZBs3z5cjg5OeHpp58GABw5cgRarRbV1dVITExERkYGXnjhBVuX1YK7u7NV/Up1tXBxdrSqr5OTAzzcnKzqaw4PDxdp2+4M1mUZ1mUZ1mUZGXXZNGjS0tJw8eJFbNq0yfThv1arBQA4Oztj6tSpyMzMNC0/fvy4qW9RUZFpXWvbLFFeXg2jUVjcDyoVqqrrLe8HoLa2AWUGg1V9O+Lh4YKysiop2+4M1mUZ1mUZ1mWZztSlVCrafINus8ub33rrLeTn5yMjIwNqtRoA8PPPP6O+/vo/yk1NTcjJyYGfnx8AICwsDGfPnsWFCxcAXL9gYMKECZ1qIyIi27PJGc2PP/6I9957DwMHDkRsbCwAoH///pgzZw6Sk5OhUCjQ1NSEgIAALFy4EMD1M5zU1FTMmzcPRqMRfn5+WLJkSafaiIjI9hRCCCvmh3o+a6fOhEqFz7+9ZNU+g/280NtBTvb3xFN1mViXZViXZXpiXbfE1BkREd2ZGDRERCQVg4aIiKRi0BARkVQMGiIikopBQ0REUjFoiIhIKgYNERFJxaAhIiKpGDRERCQVg4aIiKRi0BARkVQMGiIikopBQ0REUjFoiIhIKgYNERFJxaAhIiKpGDRERCQVg4aIiKRi0BARkVQMGiIikopBQ0REUjFoiIhIKgYNERFJxaAhIiKpGDRERCQVg4aIiKSySdBUVFTg2Wefxfjx4zFp0iQ8//zz0Ol0AIDTp09j8uTJGD9+POLi4lBeXm7qJ6ONiIhsyyZBo1AoMGfOHOTk5GDv3r24++67sXbtWhiNRiQmJiI5ORk5OTkICgrC2rVrAUBKGxER2Z5Ngkaj0WDEiBGm34cPH46ioiLk5+fDwcEBQUFBAIDY2FgcOnQIAKS0ERGR7dnZeodGoxHbt29HeHg4iouL4e3tbWpzc3OD0WhEZWWllDaNRmObP9JKCqUCNQ1NVvV1sLeDHT9xI6JbkM2DZvny5XBycsLTTz+N3NxcW+/ebO7uzlb1K9XVwsXZ0aq+Rijww+VKq/oG+nrCw82p3XU8PFys2rZsrMsyrMsyrMsyMuqyadCkpaXh4sWL2LRpE5RKJbRaLYqKikztOp0OSqUSGo1GSpslysurYTQKy/9IlQpV1fWW9wPQ2Nhkdd/a2gaUGQxttnt4uKCsrMqqbcvEuizDuizDuizTmbqUSkWbb9BtNtny1ltvIT8/HxkZGVCr1QAAf39/1NfX4+TJkwCArKwsREZGSmsjIiLbs8kZzY8//oj33nsPAwcORGxsLACgf//+yMjIwJo1a5CSkoKGhgb069cP6enpAAClUtnlbUREZHsKIYQV80M9n7VTZ0KlwuffXrJqn8N8PHDmfJlVfYP9vNDboe33DT3xVF0m1mUZ1mWZnljXLTF1RkREdyYGDRERScWgISIiqRg0REQkFYOGiIikYtAQEZFUDBoiIpKKQUNERFIxaIiISCqzg6axsRHr1q1DeHg4hg4dijFjxmDdunXQ6/Uy6yMiotuc2fc6S09PR15eHlJTU+Ht7Y2ioiJs2LAB1dXVePXVV2XWSEREtzGzg+bQoUPIzs6Gq6srAGDQoEEYPHgwoqOjGTRERNQms6fO2rr3Ju/JSURE7TE7aCIjIxEfH49jx46hoKAAR48exYIFCzBhwgSZ9RER0W3O7KmzxMREbNy4EampqSgtLYWXlxcmTpyI+fPny6yPiIhuc2YHjVqtxsKFC7Fw4UKZ9RARUQ9j0RM2v/zyS+zfvx86nQ6bNm3C2bNnUV1djZEjR8qqj4iIbnNmf0bzt7/9DcuWLcPAgQNx4sQJAICjoyPeffddacUREdHtz+yg+etf/4rMzEzMnTsXSuX1boMGDUJhYaG04oiI6PZndtDU1NRAq9UCABQKBQCgqakJ9vb2ciojIqIeweygCQ4Oxl/+8pdmy7Zu3YoRI0Z0eVFERNRzmH0xwGuvvYbnnnsOO3bsQE1NDcaPH4/evXvjvffek1kfERHd5swOGk9PT+zcuRNnz57FlStXoNVqcd9995k+ryEiImqN2SkRHx8PhUKB++67DxMmTMDw4cOhVCrx/PPPy6yPiIhuc2YHzfHjx1td/s0333RZMURE1PN0OHV243syjY2NLb4zc/nyZXh7e8upjIiIeoQOg+bq1asArt+l+cbPN2i1WiQkJJi1o7S0NOTk5ODKlSvYu3cvfHx8AADh4eFQq9VwcHAAACxatAhhYWEAgNOnTyM5ORkNDQ3o168f0tPT4e7u3qk2IiKyrQ6DZtWqVQCAgIAATJs2zeodjRkzBjNnzsR//ud/tmhbt26dKXhuMBqNSExMxKpVqxAUFIQNGzZg7dq1WLVqldVtRERke2Z/RjNt2jRUVVUhLy8P//znP5v9Z46goCDTFz7NkZ+fDwcHBwQFBQEAYmNjcejQoU61ERGR7Zl9efOuXbuQmpoKJycnODo6mpYrFAr84x//6FQRixYtghAC999/P1588UX06dMHxcXFzT7/cXNzg9FoRGVlpdVtGo2mU3XeyhRKBWoamtpsF7pa1LbT7mBvBzteqU5EEpgdNG+//TbeffddjBo1qksL2LZtG7RaLfR6PVauXInU1FSsXbu2S/dhDXd3Z6v6lepq4eLs2PGKrbC3t7O6rxEK/HC50qq+ABDo6wkPNyer+3eGh4dLt+y3I6zLMqzLMndSXWYHjcFgQGhoaJcXcGM6Ta1WY/r06YiPjzctLyoqMq2n0+mgVCqh0WisbrNEeXk1jEYrHlOtUqGqut7yfgAaG5uk9XVxdmy3vba2AWUGg1X77gwPDxeUlVXZfL8dYV2WYV2W6Yl1KZWKNt+gmz1Z8uyzz2Ljxo0wGo1WFdGa2tpaVFVd/6OEEDhw4AD8/PwAAP7+/qivr8fJkycBAFlZWYiMjOxUGxER2Z7ZZzRbtmzBtWvX8P7777c4Ozhy5EiH/VesWIHDhw/j2rVrmD17NjQaDTZt2oSEhAQYDAYYjUbcc889SElJAQAolUqsWbMGKSkpzS5T7kwbERHZnkIIYdb8UHt3AHjggQe6rKBbhbVTZ0KlwuffXrJqn8N8PHDmfJmUvh1NnQX7eaG3g0UPXO0SPXEKQSbWZRnWZRlZU2dm/8vSE8OEiIjkM/szmsbGRqxbtw5jxozB0KFDMWbMGKxbtw56vV5mfUREdJsz+4wmPT0deXl5eP311+Ht7Y2ioiJs2LAB1dXVePXVV2XWSEREtzGzg+bQoUPIzs6Gq6srAGDQoEEYPHgwoqOjGTRERNQms6fO2rpmwMxrCYiI6A5ldtBERkYiPj4ex44dQ0FBAY4ePYoFCxbwOypERNQus6fOEhMTsXHjRqSmpqK0tBReXl549NFHTd/kJyIiak2HZzTffvst0tPToVarsXDhQuTm5uLMmTM4fPgw9Ho9zp07Z4s6iYjoNtVh0Lz33nsIDg5utW3EiBHYtGlTlxdFREQ9R4dB8/3335ueePlrISEhyM/P7/KiiIio5+gwaKqrq9HY2NhqW1NTE2pqarq8KCIi6jk6DJpBgwbhiy++aLXtiy++wKBBg7q8KCIi6jk6DJpZs2YhJSUFhw8fNj0iwGg04vDhw1i2bBlmz54tvUgiIrp9dXh586RJk3Dt2jUsXrwYjY2N0Gg0qKyshL29Pf74xz8iKirKFnUSEdFtyqzv0cyePRtTp07FqVOnUFlZCY1Gg4CAADg7W/e4YyIiunOY/YVNZ2fnNq8+IyIiaovZt6AhIiKyBoOGiIikYtAQEZFUDBoiIpKKQUNERFIxaIiISCoGDRERScWgISIiqRg0REQkFYOGiIikYtAQEZFUNgmatLQ0hIeHw9fXF+fPnzctLywsRExMDMaPH4+YmBhcuHBBahsREdmeTYJmzJgx2LZtG/r169dseUpKCqZPn46cnBxMnz4dycnJUtuIiMj2bBI0QUFB0Gq1zZaVl5fj3LlzpufZREVF4dy5c9DpdFLaiIioe5j9mICuVlxcDC8vL6hUKgCASqWCp6cniouLIYTo8jY3NzeL6nN3t+5ZO6W6Wrg4O1rV197eTmrf9trVDvYQKuved/RytIOLk9qqvgDg4eFidV+ZWJdlWJdl7qS6ui1obnXl5dUwGoXlHVUqVFXXW7XPxsYmaX1dnB3bba+ubcCZ82VW7TvYzwv1NQ1W9fXwcEFZWZVVfWViXZZhXZbpiXUplYo236B3W9BotVqUlJTAYDBApVLBYDCgtLQUWq0WQogubyMiou7RbZc3u7u7w8/PD/v27QMA7Nu3D35+fnBzc5PSRkRE3UMhhLBifsgyK1aswOHDh3Ht2jW4urpCo9Fg//79KCgoQFJSEn755Rf06dMHaWlpGDRoEABIabOEtVNnQqXC599esrgfAAzz8bB6+qqjvh1NnXVm38F+XujtYN3JcU+cQpCJdVmGdVlG1tSZTYLmdsSgMR+DxnZYl2VYl2VkBQ3vDEBERFIxaIiISCoGDRERScWgISIiqRg0REQkFYOGiIikYtAQEZFUDBoiIpKKQUNERFIxaIiISCoGDRERScWgISIiqRg0REQkFYOGiIikYtAQEZFUDBoiIpKKQUNERFIxaIiISCoGDRERScWgISIiqRg0REQkFYOGiIikYtAQEZFUDBoiIpLKrrsLoNufQqlATUOTVX0da/VdXA0R3WoYNNRpDY0GnDlfZlXfUff/FoouroeIbi23RNCEh4dDrVbDwcEBALBo0SKEhYXh9OnTSE5ORkNDA/r164f09HS4u7sDgNVtRERkW7fMZzTr1q1DdnY2srOzERYWBqPRiMTERCQnJyMnJwdBQUFYu3YtAFjdRkREtnfLBM2v5efnw8HBAUFBQQCA2NhYHDp0qFNtRERke7fE1BlwfbpMCIH7778fL774IoqLi+Ht7W1qd3Nzg9FoRGVlpdVtGo3Gpn8TERHdIkGzbds2aLVa6PV6rFy5EqmpqRg3bly31uTu7mxVv1JdLVycHa3qa29vJ7Vve+2y990eDw8Xq/vKxLosw7oscyfVdUsEjVarBQCo1WpMnz4d8fHxmDlzJoqKikzr6HQ6KJVKaDQaaLVaq9osUV5eDaNRWP7HqFSoqq63vB+AxsYmaX1dnB3bbZe5746UlVVZ3VcWDw8X1mUB1mWZnliXUqlo8w16t39GU1tbi6qq63+YEAIHDhyAn58f/P39UV9fj5MnTwIAsrKyEBkZCQBWtxERke11+xlNeXk5EhISYDAYYDQacc899yAlJQVKpRJr1qxBSkpKs8uUAVjdRkREttftQXP33Xdjz549rbYFBgZi7969XdpGRES21e1TZ0RE1LMxaIiISCoGDRERScWgISIiqRg0REQkFYOGiIikYtAQEZFUDBoiIpKq27+wSXe2JoMReisfA+1gbwc7vlUiuuUxaKhbNTQacPL7Eqv6Bvt5wc6BQ5joVsf3g0REJBWDhmQpzDEAAAuCSURBVIiIpGLQEBGRVAwaIiKSikFDRERSMWiIiEgqBg0REUnFoCEiIqkYNEREJBWDpov9YWWu1X1fWvdFt/Ttzn3/8c0jVvdNePsoahqarPovbvWnVu8XQKf6d6bvpJeyu2W/ne1/Ox6vRRu+tLpvZ/vvOfZ/Vvddve1bq/u+ktG5f0fawvt30G3thJW3ryHqiO6Xhm7r//GXF/BY2CCr+p6//LPV+83/v3Kr+7aHZzRERCQVg4aIiKRi0BARkVQMGiIikooXA9Adq6adB64JXS1qrXwgGxE1x6ChO1Z7V6y5ODuiqrrehtUQ9Vw9duqssLAQMTExGD9+PGJiYnDhwoXuLomI6I7UY89oUlJSMH36dERHRyM7OxvJycnYunVrd5dFPUh7U29E9P/1yKApLy/HuXPnkJmZCQCIiorC8uXLodPp4ObmZtY2lEqFVfv2dO0FJ0f7W65vLwc7GJrabr9V6+6uvuYcr+8KdVbvu6HJ2C19rR3X5vRvr60z+74d+5rTv6cdr/b6KYQQwqqt3sLy8/OxePFi7N+/37Rs4sSJSE9Px5AhQ7qxMiKiO0+P/YyGiIhuDT0yaLRaLUpKSmAwGAAABoMBpaWl0Gq13VwZEdGdp0cGjbu7O/z8/LBv3z4AwL59++Dn52f25zNERNR1euRnNABQUFCApKQk/PLLL+jTpw/S0tIwaJB1d0MlIiLr9digISKiW0OPnDojIqJbB4OGiIikYtAQEZFUDBoiIpKqR96CRrbCwkIkJSWhsrISGo0GaWlpGDhwYLN1DAYDVqxYgWPHjkGhUGDu3LmYOnWqtJoqKirw8ssv49KlS1Cr1RgwYABSU1NbXNKdlJSEr776Cq6urgCAyMhIxMfHS6sLAMLDw6FWq+Hg4AAAWLRoEcLCwpqtU1dXh1deeQXfffcdVCoVFi9ejNGjR0ur6aeffsKCBQtMv1dVVaG6uhrffPNNs/XWr1+Pv//97/D09AQABAYGIiUlpUtrSUtLQ05ODq5cuYK9e/fCx8cHgHnjDJA31lqry9xxBsgba20dL3PGGSBvrLVWl7njDJA31tp7zU6fPo3k5GQ0NDSgX79+SE9Ph7u7e4ttdPqYCbLYjBkzxJ49e4QQQuzZs0fMmDGjxTq7d+8WcXFxwmAwiPLychEWFiYuX74sraaKigrx9ddfm35fvXq1eOWVV1qst3jxYvG3v/1NWh2tGT16tPjhhx/aXWf9+vViyZIlQgghCgsLRUhIiKiurrZFeUIIIVasWCFef/31FsvXrVsnVq9eLXXfJ06cEEVFRS2OkznjTAh5Y621uswdZ0LIG2ttHS9zxpkQ8sZaW3XdrK1xJoS8sdbWa2YwGMTYsWPFiRMnhBBCZGRkiKSkpFa30dljxqkzC924YWdUVBSA6zfsPHfuHHS65jdYPHDgAKZOnQqlUgk3NzeMHTsWhw4dklaXRqPBiBEjTL8PHz4cRUVF0vbX1Q4ePIiYmBgAwMCBA+Hv74+jR4/aZN96vR579+7FE088YZP9/VpQUFCLu1aYO84AeWOttbpuhXHWWl2WkDXWOqqru8ZZW69Zfn4+HBwcEBQUBACIjY1tc9x09pgxaCxUXFwMLy8vqFQqAIBKpYKnpyeKi4tbrOft7W36XavV4urVqzap0Wg0Yvv27QgPD2+1PTMzE5MmTcL8+fNRUFBgk5oWLVqESZMmYdmyZfjll19atBcVFaFfv36m3215vD799FN4eXm1ecPV/fv3Y9KkSYiLi8OpU6dsUpO54+zGut0x1joaZ4Dtx1pH4wzovrHW0TgD5I+1m1+zX48bNzc3GI1GVFZWtujX2WPGoOmBli9fDicnJzz99NMt2l544QXk5uZi7969iIiIwJw5c0z3hJNl27Zt+Pjjj7Fz504IIZCamip1f5bauXNnm+8yY2Nj8Y9//AN79+7FH/7wB8yfPx8VFRU2rvDW1N44A2w/1m7ncQbYZqx19JrJwqCxkLk37NRqtc2mFIqLi9G3b1/p9aWlpeHixYt45513oFS2fHm9vLxMyx977DHU1tZKfzd349io1WpMnz4d//u//9tiHW9vb1y5csX0u62OV0lJCU6cOIFJkya12u7h4QF7++vPpXnooYeg1Wrx448/Sq/LkhvDdsdY62icAbYfa+aMM6B7xlpH4wyQP9Z+/Zr9etzodDoolUpoNJoWfTt7zBg0FjL3hp2RkZHYsWMHjEYjdDodPvnkE4wfP15qbW+99Rby8/ORkZEBtVrd6jolJSWmn48dOwalUgkvLy9pNdXW1qKqqgoAIITAgQMH4Ofn12K9yMhIfPjhhwCACxcu4OzZs61eMdTVdu/ejVGjRpmujPq1m4/X999/jytXruB3v/ud9LosuTGsrceaOeMMsO1YM3ecAd0z1joaZ4Dcsdbaa+bv74/6+nqcPHkSAJCVlYXIyMhW+3f6mFl5IcMd7d///rd48sknRUREhHjyySdFQUGBEEKIOXPmiLy8PCGEEE1NTSI5OVmMGTNGjBkzRmRlZUmt6fz588LHx0dERESIyZMni8mTJ4v58+cLIYSYPHmyuHr1qhBCiGeeeUZERUWJSZMmiaeeekqcOnVKal2XLl0S0dHRIioqSkycOFEkJCSIkpKSFnXV1NSIhIQEMXbsWBERESFyc3Ol1nVDRESE+Pzzz5stu/l1fPnll8Wjjz4qJk2aJKZMmSKOHDnS5TUsX75chIWFCT8/PxESEiImTpwohGh7nP26RlljrbW62htnQthmrLVWV3vj7Nd1yRprbb2OQrQ+zoSwzVhr7zX79ttvRVRUlBg3bpyYNWuWKCsrM/XrymPGm2oSEZFUnDojIiKpGDRERCQVg4aIiKRi0BARkVQMGiIikopBQ0REUvExAUSSBQQEmH6uq6uDWq023cPs9ddfx+TJk6XXcPz4cSQmJtrsRqVEN2PQEEl2880Rw8PDsWLFCoSEhFi0jaamJtjZ8X9Xuj1x6oyom+Tl5SEmJgZBQUEIDQ1Famoq9Hq9qd3X1xfbtm1DREQEIiIiAACbN29GaGgoQkNDsWPHDvj6+uLixYsArt+GPi0tDY888ghCQkKQnJyM+vp61NbW4tlnn0VpaSkCAgIQEBDQ7HYnRLIxaIi6iVKpxCuvvIKvv/4aWVlZ+Oc//4m///3vzdb55JNP8NFHH+HAgQM4evQotmzZgszMTOTm5uL48ePN1l27di0KCwuxZ88eHD58GKWlpcjIyICTkxM2b94MT09PnDp1CqdOnZJ6fzuiX2PQEHUTf39/DB8+HHZ2dujfvz9iYmJw4sSJZuvMnTsXGo0Gjo6OOHjwIKZMmYJ7770XvXr1QkJCgmk9IQQ++ugjvPrqq9BoNHB2dsa8efOwf/9+W/9ZRC1w0peomxQWFmL16tXIz89HXV0dDAZDi4di3fxYgNLSUvj7+7faptPpUFdXhylTppiWCSFgNBol/gVE5mHQEHWTZcuWYfDgwXjzzTfh7OyMLVu2ICcnp9k6CoXC9LOnp2ezz1Zuftqmq6srHB0dsX///lanxW7eDpGtceqMqJvU1NSgd+/e6N27NwoKCrB9+/Z214+MjMSuXbtQUFCAuro6bNiwwdSmVCoxdepUvPHGGygvLwdw/fkmx44dA3D9+TaVlZWmZ7YQ2RKDhqibLF68GPv27UNgYCCWLl2KiRMntrv+qFGjMGPGDMycORPjxo3DsGHDAMD0IKvExEQMGDAA06ZNQ2BgIGbNmoXCwkIAwD333INHH30UY8eORVBQEK86I5vi82iIblMFBQWIiorC2bNn+R0buqXxjIboNpKbmwu9Xo+ff/4Z6enpGD16NEOGbnkMGqLbSFZWFkaOHIlx48ZBpVJh2bJl3V0SUYc4dUZERFLxjIaIiKRi0BARkVQMGiIikopBQ0REUjFoiIhIKgYNERFJ9f8AnII+/1i8BHQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FODko4ts5u7A",
        "colab_type": "code",
        "outputId": "e7bbe711-6f84-4d0e-e4b9-32dbadb3e37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "print(np.quantile(train_data[\"target\"],.99))\n",
        "pd.DataFrame(train_data[\"target\"]).describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>86655.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.645398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.802559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             target\n",
              "count  86655.000000\n",
              "mean       1.645398\n",
              "std        1.802559\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        1.000000\n",
              "75%        3.000000\n",
              "max       20.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57FYSITLh-0A",
        "colab_type": "text"
      },
      "source": [
        "###3.5 Distancias Coseno y Euclidiana\n",
        "\n",
        "\n",
        "En el presente apartado, calculamos la distancia coseno y la euclidiana entre las oraciones del contexto y la pregunta, dicha información, junto con la calculada en los apartados previos y posteriores, constituirán los insumos de los modelos supervisados que desarollamos en el notebook [04. modelling](https://github.com/Pilo1961/QuestionAnswer_System/blob/master/code/02.%20modelling.ipynb).\n",
        "\n",
        "En el intermedio, aprovechamos para implementar un modelo no supervisado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hinv4KbRmSDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definimos las distancias a utilizar\n",
        "norma=lambda x:np.sqrt(sum(x*x))\n",
        "distancia_coseno=lambda x,y: 1-(sum(x*y)/(norma(x)*norma(y)))\n",
        "distancia_euclidiana=lambda x,y: norma(x-y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keDGSmXiiARO",
        "colab_type": "code",
        "outputId": "c6b358f6-9964-42f2-c317-8b5c524d5395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# Calcula la distancia coseno y la euclidiana entre las oraciones del contexto y la pregunta\n",
        "# Devuevle un array target con el indice de la oracion con la minima distancia\n",
        "euclid_distance_target=[]\n",
        "cosine_distance_target=[]\n",
        "euclid_distance=[]\n",
        "cosine_distance=[]\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  dc_min=1000\n",
        "  de_min=1000\n",
        "  temp_c=[]\n",
        "  temp_e=[]\n",
        "  for j, sent_emb in enumerate(context_embedding[i]):\n",
        "    dist_euc=distancia_euclidiana(sent_emb,train_question_emb[i])\n",
        "    dist_cos=distancia_coseno(sent_emb,train_question_emb[i])  \n",
        "    temp_c.append(dist_cos)\n",
        "    temp_e.append(dist_euc)\n",
        "\n",
        "  euclid_distance_target.append(np.argmin(temp_e))\n",
        "  cosine_distance_target.append(np.argmin(temp_c))\n",
        "  euclid_distance.append(temp_e)\n",
        "  cosine_distance.append(temp_c)\n",
        "  if i%5000==0: print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5000\n",
            "10000\n",
            "15000\n",
            "20000\n",
            "25000\n",
            "30000\n",
            "35000\n",
            "40000\n",
            "45000\n",
            "50000\n",
            "55000\n",
            "60000\n",
            "65000\n",
            "70000\n",
            "75000\n",
            "80000\n",
            "85000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlash-HiaCQ",
        "colab_type": "text"
      },
      "source": [
        "#### 3.5.1 Implementación intermedia de un *modelo* no supervisado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6g3SRaZpZTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data[\"euclid_prediction\"]=euclid_distance_target\n",
        "train_data[\"cosine_prediction\"]=cosine_distance_target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DRCNSnaIshI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/My Drive/QA/dist_cosine.pkl\", 'wb') as handle:\n",
        "    pickle.dump(cosine_distance, handle)\n",
        "\n",
        "with open(\"/content/drive/My Drive/QA/dist_euclid.pkl\", 'wb') as handle:\n",
        "    pickle.dump(euclid_distance, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orTwo1Gkr-40",
        "colab_type": "text"
      },
      "source": [
        "Revisamos el accuracy  del modelo no supervisado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f73wEJor_Ck",
        "colab_type": "code",
        "outputId": "293612d8-0c9a-4581-e3a9-2401f020ffcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Checa si la oracion que minimiza la distancia es la misma que la oracion target\n",
        "euclid=0\n",
        "cosine=0\n",
        "for i in range(len(train_data)):\n",
        "  right=train_data[\"target\"][i]\n",
        "  e=train_data[\"euclid_prediction\"][i]\n",
        "  c=train_data[\"cosine_prediction\"][i]\n",
        "  if(right==e):euclid+=1\n",
        "  if(right==c):cosine+=1  \n",
        "\n",
        "print(\"Cosine accuracy\",cosine/len(train_data))\n",
        "print(\"Euclidian accuracy\",euclid/len(train_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine accuracy 0.5996191795049334\n",
            "Euclidian accuracy 0.3696613005596907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09_Ix6Fwxz8Z",
        "colab_type": "text"
      },
      "source": [
        "Usando la distancia cosento detectamos el 59.9% de las oraciones en el conjunto train.  \n",
        "Usando la distancia euclidiana detectamos el 36.9% de las oraciones en el contexto que tienen la respuesta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Z_T4EFr_NU",
        "colab_type": "code",
        "outputId": "d0e23d2a-d527-45d5-8ba2-12e90e7e5739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "#Celda para verificar consistencia\n",
        "\n",
        "i=5906\n",
        "print(\"Distancia Euclidiana\")\n",
        "print(euclid_distance[i])\n",
        "print(\"Target: \", euclid_distance_target[i])\n",
        "print(\"Index del minimo:\",np.argmin(euclid_distance[i]))\n",
        "print(\"\\n\")\n",
        "print(\"Distancia Coseno\")\n",
        "print(cosine_distance[i])\n",
        "print(\"Target: \",cosine_distance_target[i])\n",
        "print(\"Index del minimo:\",np.argmin(cosine_distance[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distancia Euclidiana\n",
            "[5.2625631927403305, 4.21635732745609, 3.5960816786122, 4.308840077891539, 4.374068086779395]\n",
            "Target:  2\n",
            "Index del minimo: 2\n",
            "\n",
            "\n",
            "Distancia Coseno\n",
            "[0.4612922809524779, 0.5593019660042353, 0.4051351904905818, 0.3781817001638521, 0.43483427939486885]\n",
            "Target:  3\n",
            "Index del minimo: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFDF3ppoydfI",
        "colab_type": "text"
      },
      "source": [
        "En la celda anterior vemos la distancia entre las oraciones del contexto y la pregunta.\n",
        "El objetivo es verificar consistencia entre el minimo y el minimo que se tiene como target registrado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXoJU1PZzvQy",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Drop observations not meeting criterias\n",
        "\n",
        "Nos limitamos a 10 oraciones por contexto. Cualquier texto con mas de 10 oraciones se limitará a 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqtOYPV8D2Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_context_embedding=pd.DataFrame(context_embedding,columns=[\"context_embedding\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBGJaXG3zcBV",
        "colab_type": "code",
        "outputId": "4d6a1fe4-6e4b-4ef8-8120-6d6249e33249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(86655, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>target</th>\n",
              "      <th>euclid_prediction</th>\n",
              "      <th>cosine_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  answer_start  ... euclid_prediction cosine_prediction\n",
              "0      0           515  ...                 0                 5\n",
              "1      1           187  ...                 3                 2\n",
              "2      2           279  ...                 3                 3\n",
              "3      3           381  ...                 3                 3\n",
              "4      4            92  ...                 3                 1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3sZ0BPqaFYQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 3.7 Root analysis\n",
        "\n",
        "En las siguientes celdas se busca la raíz de las oraciones para los contextos y para las preguntas. \n",
        "\n",
        "[Ejemplo de arboles](https://stackoverflow.com/questions/36610179/how-to-get-the-dependency-tree-with-spacy/39104235)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDTV9YKcHoeH",
        "colab_type": "code",
        "outputId": "123441f4-d3ae-41c6-e90f-4f1d9db34ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "#Ejemplo de la estructura de una oración\n",
        "\n",
        "import spacy\n",
        "from nltk import Tree\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "st = LancasterStemmer()\n",
        "\n",
        "en_nlp = spacy.load('en')\n",
        "doc = en_nlp(contexts[0][3])\n",
        "print(contexts[0][3])\n",
        "def to_nltk_tree(node):\n",
        "    if node.n_lefts + node.n_rights > 0:\n",
        "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
        "    else:\n",
        "        return node.orth_\n",
        "\n",
        "\n",
        "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "next to the main building is the basilica of the sacred heart.\n",
            "                  is                           \n",
            "  ________________|__________                   \n",
            " |        next            basilica             \n",
            " |         |            _____|_______           \n",
            " |         to          |             of        \n",
            " |         |           |             |          \n",
            " |      building       |           heart       \n",
            " |    _____|______     |      _______|_____     \n",
            " .  the          main the   the          sacred\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3bELKSgHohM",
        "colab_type": "code",
        "outputId": "e47ed3ba-132b-44d8-b8eb-3be4cc2d7d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# calcula las raices de las oraciones de los contextos\n",
        "# calcula las raices de las pregutnas\n",
        "# Genera un vector que contiene el numero de raices en cada indice\n",
        "\n",
        "questions_root=[]\n",
        "context_root=[]\n",
        "num_roots=[]\n",
        "\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  if train_data[\"context\"][i]!=last_context: \n",
        "    roots=[st.stem(str(sent.root)) for sent in en_nlp(train_data[\"context\"][i]).sents]\n",
        "  context_root.append(roots)\n",
        "  num_roots.append(len(roots))\n",
        "  questions_root.append([st.stem(str(sent.root)) for sent in en_nlp(train_data[\"question\"][i]).sents])\n",
        "  last_context=train_data[\"context\"][i]\n",
        "  if i%5000==0: print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5000\n",
            "10000\n",
            "15000\n",
            "20000\n",
            "25000\n",
            "30000\n",
            "35000\n",
            "40000\n",
            "45000\n",
            "50000\n",
            "55000\n",
            "60000\n",
            "65000\n",
            "70000\n",
            "75000\n",
            "80000\n",
            "85000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7UtYGYysQhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/My Drive/QA/question_root.pkl\", 'wb') as handle:\n",
        "    pickle.dump(questions_root, handle)\n",
        "\n",
        "with open(\"/content/drive/My Drive/QA/context_root.pkl\", 'wb') as handle:\n",
        "    pickle.dump(context_root, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKxOgWNBHowi",
        "colab_type": "code",
        "outputId": "12cdab5d-a7fc-462c-8e3c-0a3122a82f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "#hacemos un array con las posiciones en que coinciden la raiz de la pregunta y de las oraciones\n",
        "\n",
        "root_index=[]\n",
        "\n",
        "for i in range(len(questions_root)):\n",
        "  c=[]\n",
        "  a=np.array(context_root[i])\n",
        "  b=np.array(questions_root[i])\n",
        "  for root in b:\n",
        "    temp=np.where(a==root)\n",
        "    c=np.append(c,temp[0])\n",
        "  root_index.append(c.astype('i'))\n",
        "  if i%10000 ==0: print(i)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Ne2vamEY5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hace un one hot encoder de los root. Limita los resultados a las dimensiones indicadas.\n",
        "dim=9\n",
        "root_ohe=[]\n",
        "for i in range(len(root_index)):\n",
        "  a=np.zeros(60)\n",
        "  a[root_index[i]]=1\n",
        "  root_ohe.append(a[:dim])\n",
        "\n",
        "root_ohe=pd.DataFrame(root_ohe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Vz1QTaj3r1",
        "colab_type": "code",
        "outputId": "d15bc839-da24-4d49-a4a4-8109572303d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "root_ohe.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6    7    8\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0\n",
              "2  0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0\n",
              "3  0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qezc4Rk0S3Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/My Drive/QA/root_ohe.pkl\", 'wb') as handle:\n",
        "    pickle.dump(root_ohe, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyyTg3CrYxx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
